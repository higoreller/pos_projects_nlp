{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['GENSIM_DATA_DIR'] = './models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "import pandas as pd\n",
    "\n",
    "info_df = pd.DataFrame.from_dict(api.info()['models'], orient='index')\n",
    "info_df[['file_size', 'base_dataset', 'parameters']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = api.load(\"glove-wiki-gigaword-50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análise de similaridade\n",
    "v_king = model['king']\n",
    "v_queen = model['queen']\n",
    "\n",
    "print(\"Vector size:\", model.vector_size)\n",
    "print(\"v_king  =\", v_king[:10])\n",
    "print(\"v_queen =\", v_queen[:10])\n",
    "print(\"similarity:\", model.similarity('king', 'queen'))\n",
    "\n",
    "model.most_similar('king', topn=3)\n",
    "\n",
    "v_lion = model['lion']\n",
    "v_nano = model['nanotechnology']\n",
    "\n",
    "model.cosine_similarities(v_king, [v_queen, v_lion, v_nano])\n",
    "# Palavras mais similares fruto de uma subtração entre o somatório vetores\n",
    "model.most_similar(positive=['woman', 'king'], negative=['man'], topn=3)\n",
    "model.most_similar(positive=['paris', 'germany'], negative=['france'], topn=3)\n",
    "# Palavra mais similar com base apenas em um somatório\n",
    "model.most_similar(positive=['france', 'capital'], topn=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'subreddit', 'title', 'selftext', 'category_1', 'category_2',\n",
      "       'category_3', 'in_data', 'reason_for_exclusion'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "posts_df = pd.read_csv(\"/home/higoreller/pos_projects/datasets/class_6/rspct.tsv\", sep='\\t')\n",
    "subred_df = pd.read_csv(\"/home/higoreller/pos_projects/datasets/class_6/subreddit_info.csv\").set_index(['subreddit'])\n",
    "df = posts_df.join(subred_df, on='subreddit')\n",
    "df.head(5)\n",
    "print(df.columns)\n",
    "column_mapping = {\n",
    "    'id': 'id',\n",
    "    'subreddit': 'subreddit',\n",
    "    'title': 'title',\n",
    "    'selftext': 'text',\n",
    "    'category_1': 'category',\n",
    "    'category_2': 'subcategory',\n",
    "    'category_3': None, # no data\n",
    "    'in_data': None, # not needed\n",
    "    'reason_for_exclusion': None # not needed\n",
    "}\n",
    "# define remaining columns\n",
    "columns = [c for c in column_mapping.keys() if column_mapping[c] != None]\n",
    "\n",
    "# select and rename those columns\n",
    "df = df[columns].rename(columns=column_mapping)\n",
    "df = df[df['category'] == 'autos']\n",
    "df.to_pickle(\"reddit_dataframe.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "DatabaseError",
     "evalue": "Execution failed on sql 'select subreddit, lemmas, text from posts_nlp': no such table: posts_nlp",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m~/pos_projects/venv/lib/python3.8/site-packages/pandas/io/sql.py:2020\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/higoreller/pos_projects/venv/lib/python3.8/site-packages/pandas/io/sql.py?line=2018'>2019</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///home/higoreller/pos_projects/venv/lib/python3.8/site-packages/pandas/io/sql.py?line=2019'>2020</a>\u001b[0m     cur\u001b[39m.\u001b[39;49mexecute(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/higoreller/pos_projects/venv/lib/python3.8/site-packages/pandas/io/sql.py?line=2020'>2021</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m cur\n",
      "\u001b[0;31mOperationalError\u001b[0m: no such table: posts_nlp",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m/home/higoreller/pos_projects/src/pos_references/class_6/blueprints_chapter_10.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/higoreller/pos_projects/src/pos_references/class_6/blueprints_chapter_10.ipynb#ch0000013vscode-remote?line=0'>1</a>\u001b[0m db_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/home/higoreller/pos_projects/datasets/reddit-selfposts.db\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/higoreller/pos_projects/src/pos_references/class_6/blueprints_chapter_10.ipynb#ch0000013vscode-remote?line=1'>2</a>\u001b[0m con \u001b[39m=\u001b[39m sqlite3\u001b[39m.\u001b[39mconnect(db_name)\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/higoreller/pos_projects/src/pos_references/class_6/blueprints_chapter_10.ipynb#ch0000013vscode-remote?line=2'>3</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_sql(\u001b[39m\"\u001b[39;49m\u001b[39mselect subreddit, lemmas, text from posts_nlp\u001b[39;49m\u001b[39m\"\u001b[39;49m, con)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/higoreller/pos_projects/src/pos_references/class_6/blueprints_chapter_10.ipynb#ch0000013vscode-remote?line=3'>4</a>\u001b[0m con\u001b[39m.\u001b[39mclose()\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/higoreller/pos_projects/src/pos_references/class_6/blueprints_chapter_10.ipynb#ch0000013vscode-remote?line=5'>6</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mlemmas\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mlemmas\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39mlower()\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39msplit() \u001b[39m# lower case tokens\u001b[39;00m\n",
      "File \u001b[0;32m~/pos_projects/venv/lib/python3.8/site-packages/pandas/io/sql.py:566\u001b[0m, in \u001b[0;36mread_sql\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize)\u001b[0m\n\u001b[1;32m    <a href='file:///home/higoreller/pos_projects/venv/lib/python3.8/site-packages/pandas/io/sql.py?line=562'>563</a>\u001b[0m pandas_sql \u001b[39m=\u001b[39m pandasSQL_builder(con)\n\u001b[1;32m    <a href='file:///home/higoreller/pos_projects/venv/lib/python3.8/site-packages/pandas/io/sql.py?line=564'>565</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(pandas_sql, SQLiteDatabase):\n\u001b[0;32m--> <a href='file:///home/higoreller/pos_projects/venv/lib/python3.8/site-packages/pandas/io/sql.py?line=565'>566</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m pandas_sql\u001b[39m.\u001b[39;49mread_query(\n\u001b[1;32m    <a href='file:///home/higoreller/pos_projects/venv/lib/python3.8/site-packages/pandas/io/sql.py?line=566'>567</a>\u001b[0m         sql,\n\u001b[1;32m    <a href='file:///home/higoreller/pos_projects/venv/lib/python3.8/site-packages/pandas/io/sql.py?line=567'>568</a>\u001b[0m         index_col\u001b[39m=\u001b[39;49mindex_col,\n\u001b[1;32m    <a href='file:///home/higoreller/pos_projects/venv/lib/python3.8/site-packages/pandas/io/sql.py?line=568'>569</a>\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    <a href='file:///home/higoreller/pos_projects/venv/lib/python3.8/site-packages/pandas/io/sql.py?line=569'>570</a>\u001b[0m         coerce_float\u001b[39m=\u001b[39;49mcoerce_float,\n\u001b[1;32m    <a href='file:///home/higoreller/pos_projects/venv/lib/python3.8/site-packages/pandas/io/sql.py?line=570'>571</a>\u001b[0m         parse_dates\u001b[39m=\u001b[39;49mparse_dates,\n\u001b[1;32m    <a href='file:///home/higoreller/pos_projects/venv/lib/python3.8/site-packages/pandas/io/sql.py?line=571'>572</a>\u001b[0m         chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[1;32m    <a href='file:///home/higoreller/pos_projects/venv/lib/python3.8/site-packages/pandas/io/sql.py?line=572'>573</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///home/higoreller/pos_projects/venv/lib/python3.8/site-packages/pandas/io/sql.py?line=574'>575</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/higoreller/pos_projects/venv/lib/python3.8/site-packages/pandas/io/sql.py?line=575'>576</a>\u001b[0m     _is_table_name \u001b[39m=\u001b[39m pandas_sql\u001b[39m.\u001b[39mhas_table(sql)\n",
      "File \u001b[0;32m~/pos_projects/venv/lib/python3.8/site-packages/pandas/io/sql.py:2080\u001b[0m, in \u001b[0;36mSQLiteDatabase.read_query\u001b[0;34m(self, sql, index_col, coerce_float, params, parse_dates, chunksize, dtype)\u001b[0m\n\u001b[1;32m   <a href='file:///home/higoreller/pos_projects/venv/lib/python3.8/site-packages/pandas/io/sql.py?line=2067'>2068</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread_query\u001b[39m(\n\u001b[1;32m   <a href='file:///home/higoreller/pos_projects/venv/lib/python3.8/site-packages/pandas/io/sql.py?line=2068'>2069</a>\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   <a href='file:///home/higoreller/pos_projects/venv/lib/python3.8/site-packages/pandas/io/sql.py?line=2069'>2070</a>\u001b[0m     sql,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///home/higoreller/pos_projects/venv/lib/python3.8/site-packages/pandas/io/sql.py?line=2075'>2076</a>\u001b[0m     dtype: DtypeArg \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   <a href='file:///home/higoreller/pos_projects/venv/lib/python3.8/site-packages/pandas/io/sql.py?line=2076'>2077</a>\u001b[0m ):\n\u001b[1;32m   <a href='file:///home/higoreller/pos_projects/venv/lib/python3.8/site-packages/pandas/io/sql.py?line=2078'>2079</a>\u001b[0m     args \u001b[39m=\u001b[39m _convert_params(sql, params)\n\u001b[0;32m-> <a href='file:///home/higoreller/pos_projects/venv/lib/python3.8/site-packages/pandas/io/sql.py?line=2079'>2080</a>\u001b[0m     cursor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexecute(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m   <a href='file:///home/higoreller/pos_projects/venv/lib/python3.8/site-packages/pandas/io/sql.py?line=2080'>2081</a>\u001b[0m     columns \u001b[39m=\u001b[39m [col_desc[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m col_desc \u001b[39min\u001b[39;00m cursor\u001b[39m.\u001b[39mdescription]\n\u001b[1;32m   <a href='file:///home/higoreller/pos_projects/venv/lib/python3.8/site-packages/pandas/io/sql.py?line=2082'>2083</a>\u001b[0m     \u001b[39mif\u001b[39;00m chunksize \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/pos_projects/venv/lib/python3.8/site-packages/pandas/io/sql.py:2032\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/higoreller/pos_projects/venv/lib/python3.8/site-packages/pandas/io/sql.py?line=2028'>2029</a>\u001b[0m     \u001b[39mraise\u001b[39;00m ex \u001b[39mfrom\u001b[39;00m \u001b[39minner_exc\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/higoreller/pos_projects/venv/lib/python3.8/site-packages/pandas/io/sql.py?line=2030'>2031</a>\u001b[0m ex \u001b[39m=\u001b[39m DatabaseError(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExecution failed on sql \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00margs[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mexc\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> <a href='file:///home/higoreller/pos_projects/venv/lib/python3.8/site-packages/pandas/io/sql.py?line=2031'>2032</a>\u001b[0m \u001b[39mraise\u001b[39;00m ex \u001b[39mfrom\u001b[39;00m \u001b[39mexc\u001b[39;00m\n",
      "\u001b[0;31mDatabaseError\u001b[0m: Execution failed on sql 'select subreddit, lemmas, text from posts_nlp': no such table: posts_nlp"
     ]
    }
   ],
   "source": [
    "db_name = \"/home/higoreller/pos_projects/datasets/class_6/reddit-selfposts.db\"\n",
    "con = sqlite3.connect(db_name)\n",
    "df = pd.read_sql(\"select subreddit, lemmas, text from posts_nlp\", con)\n",
    "con.close()\n",
    "\n",
    "df['lemmas'] = df['lemmas'].str.lower().str.split() # lower case tokens\n",
    "sents = df['lemmas'] # our training \"sentences\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.phrases import Phrases, npmi_scorer\n",
    "\n",
    "phrases = Phrases(sents, min_count=10, threshold=0.3, delimiter=b'-', scoring=npmi_scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = \"I had to replace the timing belt in my mercedes c300\".split()\n",
    "phrased = phrases[sent]\n",
    "print('|'.join(phrased))\n",
    "\n",
    "\"\"\"I|had|to|replace|the|timing-belt|in|my|mercedes-c300\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_df = pd.DataFrame(phrases.export_phrases(sents),\n",
    "                         columns =['phrase', 'score'])\n",
    "phrase_df = phrase_df[['phrase', 'score']].drop_duplicates() \\\n",
    "            .sort_values(by='score', ascending=False).reset_index(drop=True)\n",
    "phrase_df['phrase'] = phrase_df['phrase'].map(lambda p: p.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_df[phrase_df['phrase'].str.contains('mercedes')]\n",
    "\n",
    "\"\"\"mercedes c300 => 0.47 / mercedez benz => 0.80\"\"\""
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1ceb72ab40b575b45c4814ba1628d43a0bb7e2099d88da0668b141d787e76c17"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
